# Provider & Accounts Architecture Redesign

## Problem Statement

The current architecture treats model configuration as a manual, flat process:
users create TOML files with raw CLI flags, organize them into "pools" by
command set, and manage parameters by hand. This has several problems:

1. **Users see implementation details** â€” raw flags like `--dangerously-bypass-approvals`,
   `-c model_reasoning_effort=high`, `-m gpt-5.3-codex` are exposed directly
2. **No model discovery** â€” users must know what models exist and how to configure them
3. **No account management** â€” "pools" conflate CLI tools with auth profiles
4. **No parameter intelligence** â€” the system doesn't know what parameters are legal
   for a given model or how to present them
5. **No version tracking** â€” CLI updates can silently break configurations
6. **No quotas** â€” users can't see their remaining usage

## Core Insight

What we call "pools" are really **accounts** â€” different authentication profiles
for the same provider CLI tool. A user doesn't think "I have a claude pool with
codex commands." They think "I have two Anthropic accounts and three OpenAI
accounts, and I want to run claude-sonnet-4 load-balanced across all of them."

## New Mental Model

```
Provider (CLI tool: claude, codex, gemini, opencode)
  â””â”€â”€ Account (auth profile within that CLI)
       â””â”€â”€ Model (discovered from CLI, with typed parameters)
```

### Example

```
Anthropic (claude CLI v1.2.3)
  â”œâ”€â”€ Account: "work"     (OAuth via claude CLI)
  â”œâ”€â”€ Account: "personal" (API key: ANTHROPIC_API_KEY)
  â””â”€â”€ Available Models:
       â”œâ”€â”€ claude-sonnet-4  (params: extended_thinking, max_tokens)
       â””â”€â”€ claude-haiku-4   (params: max_tokens)

OpenAI (codex CLI v0.9.1)
  â”œâ”€â”€ Account: "team-a"   (API key: OPENAI_API_KEY)
  â”œâ”€â”€ Account: "team-b"   (API key via codex config)
  â””â”€â”€ Available Models:
       â”œâ”€â”€ gpt-5.3-codex   (params: reasoning_effort)
       â””â”€â”€ o3               (params: reasoning_effort, temperature)

Google (gemini CLI v2.0.0)
  â”œâ”€â”€ Account: "default"  (OAuth via gemini CLI)
  â””â”€â”€ Available Models:
       â”œâ”€â”€ gemini-3-pro     (params: thinking_budget)
       â””â”€â”€ gemini-3-flash   (params: thinking_budget)
```

### Load Balancing Across Everything

When the user asks for `claude-sonnet-4`, we can load-balance across ALL
accounts from ALL providers that offer it. If both Anthropic and a hypothetical
third-party provider support the same model, we balance across all of them.

```
Target: claude-sonnet-4
  â”œâ”€â”€ Anthropic/work     â†’ claude --profile work --model sonnet-4
  â”œâ”€â”€ Anthropic/personal â†’ claude --api-key $KEY --model sonnet-4
  â””â”€â”€ ThirdParty/main    â†’ thirdparty exec -m claude-sonnet-4
```

The existing balancer (round-robin + error avoidance via SQLite) already
supports this â€” we just need to map accounts to providers properly.

---

## Data Model

### Current â†’ New Mapping

| Current | New | Notes |
|---------|-----|-------|
| Model TOML file | Model (discovered) | No longer manually created |
| Pool (command set) | Provider + Accounts | Pools were really auth profiles |
| Provider args | Parameters (typed) | Friendly names, AI-discovered |
| `model_names[]` | Available models per provider | Discovered from CLI |

### New Entities

#### Provider

A CLI tool that can execute AI model requests.

```rust
struct Provider {
    cli_name: String,         // "claude", "codex", "gemini", "opencode"
    display_name: String,     // "Anthropic", "OpenAI", "Google"
    installed: bool,
    version: Option<String>,  // detected CLI version
    config_dir: Option<String>,
    auth_methods: Vec<AuthMethod>,  // what auth this CLI supports
    models: Vec<DiscoveredModel>,   // what models this CLI knows about
    last_synced: Option<DateTime>,  // when we last queried the CLI
}

enum AuthMethod {
    OAuth,                    // CLI handles the flow
    ApiKey {
        env_var: String,      // e.g., "ANTHROPIC_API_KEY"
        config_path: Option<String>,  // alternative file-based location
    },
    ConfigFile {
        path: String,         // e.g., "~/.codex/config.toml"
    },
}
```

#### Account

An authenticated profile within a provider CLI.

```rust
struct Account {
    id: String,               // user-chosen label: "work", "personal", "team-a"
    provider: String,         // which CLI
    profile_name: String,     // CLI-specific profile identifier
    auth_method: AuthMethod,  // how this account authenticates
    auth_status: AuthStatus,  // valid, expired, unknown
    quotas: Option<QuotaInfo>,
    created_at: DateTime,
}

enum AuthStatus {
    Valid,
    Expired,
    Unknown,     // haven't checked yet
    NoAuth,      // CLI doesn't require auth for this profile
}

struct QuotaInfo {
    requests_remaining: Option<u64>,
    tokens_remaining: Option<u64>,
    reset_at: Option<DateTime>,
    raw: serde_json::Value,   // provider-specific quota data
    fetched_at: DateTime,
}
```

#### Discovered Model

A model that a provider CLI knows about, with typed parameters.

```rust
struct DiscoveredModel {
    canonical_name: String,   // "claude-sonnet-4", "gpt-5.3-codex"
    provider: String,         // which CLI discovered this
    parameters: Vec<Parameter>,
    discovered_at: DateTime,
    cli_version: String,      // CLI version when discovered
}

struct Parameter {
    name: String,             // friendly: "reasoning_effort", "max_tokens"
    param_type: ParamType,
    description: String,      // AI-generated description
    cli_mapping: CliMapping,  // hidden from user
}

enum ParamType {
    Enum { options: Vec<String> },  // e.g., ["low", "medium", "high", "xhigh"]
    String,
    Number { min: Option<f64>, max: Option<f64> },
    Boolean,
}

/// How a friendly parameter maps to actual CLI arguments.
/// Hidden from the user entirely â€” they never see dashes or flags.
struct CliMapping {
    flag: String,             // e.g., "-c", "--model", "--reasoning-effort"
    value_template: String,   // e.g., "{value}", "model_reasoning_effort={value}"
}
```

#### Model Selection (replaces current ModelConfig)

What the user actually configures: "I want to use this model with these
parameter values, load-balanced across these accounts."

```rust
struct ModelSelection {
    name: String,                    // user-facing name for this config
    canonical_model: String,         // "claude-sonnet-4"
    parameter_values: HashMap<String, String>,  // friendly_name â†’ value
    accounts: Vec<AccountRef>,       // which accounts to use
    prompt_mode: PromptMode,         // stdin or arg
}

struct AccountRef {
    provider: String,        // CLI name
    account_id: String,      // account label
}
```

---

## Security Model

### OAuth Token Handling

**Rule: OAuth tokens are NEVER used outside the provider's own CLI unless
the user gives EXPLICIT permission.**

OAuth tokens obtained through a provider's CLI belong to that provider's
ecosystem. Using them outside the CLI (e.g., direct API calls) may violate
ToS and result in account bans.

```
OAuth Token Flow:
  1. User initiates auth â†’ we call provider CLI's auth command
  2. CLI handles OAuth flow (browser redirect, token exchange)
  3. CLI stores token in its own config
  4. We ONLY invoke the CLI to use the token
  5. We NEVER read, extract, or reuse the OAuth token directly

API Key Flow:
  1. User provides API key â†’ we store in env var or config
  2. We can use API key for direct API calls (quota checks, etc.)
  3. We can pass API key to any compatible CLI tool
```

### Permission Levels

```
              OAuth Token        API Key
              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€
Use via CLI:  ALWAYS OK          ALWAYS OK
Direct API:   EXPLICIT ONLY      OK
Cross-CLI:    EXPLICIT ONLY      OK (if compatible)
Quota check:  VIA CLI ONLY       DIRECT API OK
```

### Secret Storage

Secrets (API keys, tokens) are managed by the provider CLIs themselves.
We do NOT store secrets. We store:

- Which accounts exist and how they authenticate
- Account labels and metadata
- Auth status (valid/expired) â€” checked by probing the CLI

For CI/CD, users configure secrets via GitHub Secrets or equivalent.
Our config files contain NO secrets â€” only references (env var names,
profile names).

---

## AI Agent Architecture

### Agent Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Opus                       â”‚
â”‚  CLI version research, contract discovery,   â”‚
â”‚  parameter introspection, integration        â”‚
â”‚  script generation                           â”‚
â”‚  (background, triggered by version changes)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ creates/updates
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Sonnet                      â”‚
â”‚  Complex tasks, tool generation, agent       â”‚
â”‚  creation, multi-step configuration          â”‚
â”‚  (background, escalated from Haiku)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ creates/updates
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Haiku                       â”‚
â”‚  User-facing chat, simple config changes,    â”‚
â”‚  parameter explanations, quick actions       â”‚
â”‚  (interactive, on every panel + main page)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Haiku: User-Facing Assistant

Every panel and the main page has a "What would you like to do?" chatbox
powered by Haiku. Haiku handles:

- Explaining what parameters do
- Simple configuration changes ("set reasoning effort to high")
- Answering questions ("what models does my codex account support?")
- Navigating the UI ("show me my OpenAI accounts")

Haiku has access to:
- Current provider/account/model state
- Parameter documentation (AI-generated, cached)
- The user's current panel context

When Haiku can't handle something, it escalates to Sonnet in the background
and tells the user it's working on it.

### Sonnet: Complex Task Handler

Sonnet handles tasks that require multi-step reasoning or tool creation:

- Creating new integration scripts for a provider
- Configuring complex model setups
- Building specialized agents for a provider pool
- Resolving configuration conflicts

Sonnet creates:
- **Tools**: Provider-specific utilities (auth checkers, model listers)
- **Agents**: Specialized assistants for each provider/panel

### Opus: Research & Discovery

Opus handles broad research tasks triggered by system events:

- CLI version change detected â†’ research new capabilities, parameters,
  breaking changes
- New provider added â†’ discover auth methods, model catalog, parameter
  schemas
- Contract changes â†’ update internal parameter mappings, regenerate UIs

Opus output feeds into the parameter/model discovery system, updating
what Haiku and Sonnet know about.

### Specialized Agents

Each provider pool gets its own specialized agent, created by Sonnet:

```
agents/
  â”œâ”€â”€ provider-anthropic.md     # knows claude CLI specifics
  â”œâ”€â”€ provider-openai.md        # knows codex CLI specifics
  â”œâ”€â”€ provider-google.md        # knows gemini CLI specifics
  â””â”€â”€ panel-model-config.md     # knows model parameter mapping
```

These agents are regenerated when CLI versions change.

---

## Provider Integration Scripts

Each provider needs an integration layer that knows how to:

1. **Detect** â€” is the CLI installed? what version?
2. **Authenticate** â€” initiate auth flow through CLI
3. **List profiles** â€” enumerate existing accounts/profiles
4. **Create profile** â€” set up a new account/profile
5. **List models** â€” query what models are available
6. **Discover parameters** â€” for each model, what parameters exist
7. **Check quotas** â€” fetch remaining usage (respecting auth type)
8. **Execute** â€” run a prompt against a specific account+model+params

These are written per-provider pool (not per-provider), because pools share
the same CLI tool and differ only in auth context.

### Example: Claude CLI Integration

```
detect:
  which claude â†’ path
  claude --version â†’ version string

authenticate:
  claude auth login --profile {profile_name}
  # CLI handles OAuth browser flow

list_profiles:
  claude auth list
  # or scan ~/.claude/profiles/

list_models:
  claude models list
  # parse output for model names

discover_parameters:
  # AI-driven: read claude --help, claude models info {model}
  # extract parameter names, types, valid values

check_quotas:
  # OAuth: claude usage --profile {profile} (must go through CLI)
  # API key: direct API call to /v1/usage

execute:
  claude --profile {profile} --model {model} {param_flags} {prompt}
```

### Version-Aware Integration

Integration scripts are tagged with the CLI version they were written for:

```
integration:
  provider: claude
  cli_version: "1.2.3"
  last_verified: "2026-02-19"
```

When a version change is detected:
1. System flags the integration as potentially stale
2. Opus researches the changelog / new --help output
3. Opus updates parameter mappings and integration scripts
4. Sonnet regenerates specialized agents
5. Haiku's knowledge is refreshed

---

## CLI Version Detection

### Continuous Monitoring

On app startup and periodically:

```
1. For each known provider:
   a. Run `which {cli}` â†’ check if still installed
   b. Run `{cli} --version` â†’ compare to stored version
   c. If version changed:
      - Flag integration as stale
      - Queue Opus research task
      - Notify user: "codex updated to v0.10.0, re-syncing..."
   d. If newly installed:
      - Queue full discovery (auth methods, models, params)
```

### Version Change Response

```
Version Change Detected
  â”‚
  â”œâ”€â–º Opus: Research new version
  â”‚    â”œâ”€ Read changelog / release notes
  â”‚    â”œâ”€ Run {cli} --help, {cli} models --help, etc.
  â”‚    â”œâ”€ Compare old vs new parameter schemas
  â”‚    â””â”€ Output: updated DiscoveredModel[] + breaking changes
  â”‚
  â”œâ”€â–º Sonnet: Update integrations
  â”‚    â”œâ”€ Regenerate integration scripts
  â”‚    â”œâ”€ Update specialized agents
  â”‚    â””â”€ Fix any broken configurations
  â”‚
  â””â”€â–º Haiku: Inform user
       â””â”€ "codex updated: 2 new models, reasoning_effort now supports 'ultra'"
```

---

## UI Design

### Main Page

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent Runner                                    [+] [âš™] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€ Anthropic (claude v1.2.3) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Accounts: [work] [personal]              [+ Add]  â”‚  â”‚
â”‚  â”‚  Models:   claude-sonnet-4  claude-haiku-4          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€ OpenAI (codex v0.9.1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Accounts: [team-a] [team-b]              [+ Add]  â”‚  â”‚
â”‚  â”‚  Models:   gpt-5.3-codex  o3                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€ Google (gemini v2.0.0) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Accounts: [default]                      [+ Add]  â”‚  â”‚
â”‚  â”‚  Models:   gemini-3-pro  gemini-3-flash             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ’¬ What would you like to do?                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [Send]â”‚   â”‚
â”‚  â”‚  â”‚ "Add a new OpenAI account for my team"        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Provider Panel (slide-in)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â—€ Anthropic                        â”‚
â”‚  claude CLI v1.2.3                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  Accounts                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ work         OAuth    [âœ“]    â”‚   â”‚
â”‚  â”‚              Quota: 89%      â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ personal     API Key  [âœ“]    â”‚   â”‚
â”‚  â”‚              Quota: 45%      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  [+ Add Account]                     â”‚
â”‚                                      â”‚
â”‚  Models                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ claude-sonnet-4               â”‚   â”‚
â”‚  â”‚   extended_thinking: [on/off] â”‚   â”‚
â”‚  â”‚   max_tokens: [4096      ]    â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ claude-haiku-4                â”‚   â”‚
â”‚  â”‚   max_tokens: [4096      ]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ ğŸ’¬ Ask about this provider  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CLI: /usr/local/bin/claude          â”‚
â”‚  Config: ~/.claude                   â”‚
â”‚  Last synced: 2 min ago  [â†» Sync]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Configuration Panel (slide-in)

When clicking a model, shows friendly parameter names â€” never raw flags:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â—€ claude-sonnet-4                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  Parameters                          â”‚
â”‚                                      â”‚
â”‚  Reasoning Effort                    â”‚
â”‚  â—‹ low  â—‹ medium  â— high  â—‹ xhigh   â”‚
â”‚                                      â”‚
â”‚  Max Tokens                          â”‚
â”‚  [4096                          ]    â”‚
â”‚                                      â”‚
â”‚  Extended Thinking                   â”‚
â”‚  [âœ“] Enabled                         â”‚
â”‚                                      â”‚
â”‚  Load Balance Across                 â”‚
â”‚  [âœ“] Anthropic / work               â”‚
â”‚  [âœ“] Anthropic / personal           â”‚
â”‚  [ ] ThirdParty / main              â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ ğŸ’¬ Ask about this model     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Save & Test]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Parameters are rendered dynamically based on `ParamType`:
- `Enum` â†’ radio buttons or chips
- `Boolean` â†’ toggle/checkbox
- `Number` â†’ number input with min/max
- `String` â†’ text input

The user never sees `-c model_reasoning_effort=high`. They see
"Reasoning Effort: high". The `CliMapping` handles translation internally.

---

## Faceted Grouping (Retained)

The `~` separator in filenames is still useful for our internal config layer.
When we create a `ModelSelection`, the filename encodes the model + parameter
variant:

```
claude-sonnet-4~high.toml     â†’ model: claude-sonnet-4, reasoning_effort: high
claude-sonnet-4~low.toml      â†’ model: claude-sonnet-4, reasoning_effort: low
```

This enables the faceted chip UI in the model list â€” users see grouped
variants rather than a flat list. The grouping is purely a UI concern and
doesn't affect the backend data model.

The difference from the current approach: facets are now derived from
discovered parameters rather than manually named. The system knows that
"high" and "low" are values of the "reasoning_effort" parameter because
it discovered that from the CLI.

---

## Migration Path

### Phase 1: Provider & Account Layer (Backend)

1. Add `Provider` entity to SQLite (replaces implicit pool detection)
2. Add `Account` entity to SQLite (replaces pool command grouping)
3. Add provider integration trait/interface
4. Implement claude CLI integration (detect, auth, list models)
5. Implement codex CLI integration
6. Implement gemini CLI integration

### Phase 2: Model Discovery (Backend + AI)

1. Build parameter discovery pipeline (AI-driven, reads CLI help)
2. Store `DiscoveredModel` + `Parameter` in SQLite
3. Build `CliMapping` translator (friendly name â†’ raw flags)
4. Add CLI version tracking + staleness detection
5. Implement quota fetching (per auth type)

### Phase 3: UI Redesign (Frontend)

1. Replace PoolCard with ProviderCard (accounts + models)
2. Build dynamic parameter UI (rendered from ParamType)
3. Add chatbox component (Haiku-powered)
4. Build account management panel (add/remove accounts, auth flows)
5. Build model configuration panel (friendly parameters, load balancing)

### Phase 4: Agent Infrastructure

1. Build Haiku chat integration (per-panel + main page)
2. Build Sonnet escalation pipeline
3. Build Opus research pipeline (CLI version change â†’ discovery)
4. Generate specialized provider agents
5. Build tool creation system (Sonnet creates provider-specific tools)

### Phase 5: Advanced Features

1. Cross-provider load balancing for same model
2. Quota-aware routing (prefer accounts with remaining quota)
3. Real-time quota display
4. Auto-update on CLI version changes
5. Integration script marketplace / sharing

---

## Storage Layout (New)

```
~/.config/oulipoly-agent-runner/
  â”œâ”€â”€ config.toml                    # global settings
  â”œâ”€â”€ models/                        # ModelSelection TOML files (faceted)
  â”‚   â”œâ”€â”€ claude-sonnet-4~high.toml
  â”‚   â”œâ”€â”€ claude-sonnet-4~low.toml
  â”‚   â””â”€â”€ gpt-5.3-codex~medium.toml
  â””â”€â”€ agents/                        # agent configs (some auto-generated)
       â”œâ”€â”€ provider-anthropic.md
       â”œâ”€â”€ provider-openai.md
       â””â”€â”€ user-custom.md

~/.local/share/oulipoly-agent-runner/
  â””â”€â”€ state.db                       # SQLite (extended schema)
       â”œâ”€â”€ providers                 # installed CLIs + versions
       â”œâ”€â”€ accounts                  # auth profiles per provider
       â”œâ”€â”€ discovered_models         # models found in CLIs
       â”œâ”€â”€ parameters                # typed params per model
       â”œâ”€â”€ cli_mappings              # friendly name â†’ raw flag
       â”œâ”€â”€ provider_states           # invocation counts, errors
       â”œâ”€â”€ invocations               # execution history
       â””â”€â”€ memory_*                  # graph + sessions (existing)
```

---

## Open Questions

1. **Profile enumeration**: How does each CLI expose its profiles? Do they
   all support `--profile`? Or is it env vars, config files, etc.? Needs
   per-provider research.

2. **Model catalog**: Do CLIs expose their full model catalog programmatically,
   or do we need to scrape `--help` output and documentation? Likely varies
   per provider.

3. **Parameter schema**: Is there a machine-readable way to get parameter
   schemas from CLIs, or is this always AI-driven discovery? Some CLIs may
   have `--help --json` or similar.

4. **Quota APIs**: Which providers expose quota/usage APIs? What are the
   endpoints? Are there rate limits on checking quotas?

5. **Cross-provider model identity**: How do we determine that "claude-sonnet-4"
   on Anthropic's CLI is the same model as "claude-sonnet-4" on a third-party
   CLI? Canonical model name registry?

6. **Offline mode**: What happens when a CLI is unavailable? Cache last-known
   model catalog and parameters? Allow execution attempts anyway?

7. **Multi-user**: If multiple users share a machine, how do we handle
   conflicting CLI configs? Probably out of scope â€” each user has their own
   `~/.config`.
